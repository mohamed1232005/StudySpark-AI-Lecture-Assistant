{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "818e87501e634a76956e3b321cf46419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7080f098729540b6aa21f9a67423aa6e",
              "IPY_MODEL_61004b4df7154c1288ed0e57d2ca9559",
              "IPY_MODEL_b96c260e7af949ce98eb7d6a4023edac"
            ],
            "layout": "IPY_MODEL_92f45af4e9a64a549f27bf7eebeabb79"
          }
        },
        "7080f098729540b6aa21f9a67423aa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43b53feb54fb4bd3ac852cf2190c6a18",
            "placeholder": "​",
            "style": "IPY_MODEL_e502db45e79f41378d35e0fc3cb2e704",
            "value": "Fetching 0 files: "
          }
        },
        "61004b4df7154c1288ed0e57d2ca9559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ed548d07174722bf72dac387c78927",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_769f618ac31f4485af855bff573a01ef",
            "value": 0
          }
        },
        "b96c260e7af949ce98eb7d6a4023edac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a154c595dc314126aadce8ec41640f17",
            "placeholder": "​",
            "style": "IPY_MODEL_077ad37b972e4c4da0e0469dcc960a06",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "92f45af4e9a64a549f27bf7eebeabb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b53feb54fb4bd3ac852cf2190c6a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e502db45e79f41378d35e0fc3cb2e704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ed548d07174722bf72dac387c78927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "769f618ac31f4485af855bff573a01ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a154c595dc314126aadce8ec41640f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077ad37b972e4c4da0e0469dcc960a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217c98a8e4b54fa78852a9915f818530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88f6c2c189bf41b2bb3a59dc57367b59",
              "IPY_MODEL_767ede16753f4b4ab92bbaedd424287c",
              "IPY_MODEL_37747e36e25547299466ca088222d0fc"
            ],
            "layout": "IPY_MODEL_d2db485f93ca4f8cabf186838f313249"
          }
        },
        "88f6c2c189bf41b2bb3a59dc57367b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f71e581b1945ac9673ce13dc1a9bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_dec1996275714873964c55045b80aba1",
            "value": "Fetching 1 files: 100%"
          }
        },
        "767ede16753f4b4ab92bbaedd424287c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8d4028328f4d58a6a6c3f7f423b3cc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edc1cb4ed1f54016a0736e61bf54b276",
            "value": 1
          }
        },
        "37747e36e25547299466ca088222d0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb03d2c09ee425682fdb0d32c984a72",
            "placeholder": "​",
            "style": "IPY_MODEL_63e46d4b205a4fe5a302d76f8200367b",
            "value": " 1/1 [00:00&lt;00:00, 109.89it/s]"
          }
        },
        "d2db485f93ca4f8cabf186838f313249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f71e581b1945ac9673ce13dc1a9bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec1996275714873964c55045b80aba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad8d4028328f4d58a6a6c3f7f423b3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc1cb4ed1f54016a0736e61bf54b276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fb03d2c09ee425682fdb0d32c984a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e46d4b205a4fe5a302d76f8200367b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65c1e2c6f87140b5b2db45f8dcb60dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67e437f3858f47c08dab7223acb4b0c8",
              "IPY_MODEL_3fa75dbb80a240c8a71332448bdf2e78",
              "IPY_MODEL_4f93b0b47daf4f91b154236e2def63df"
            ],
            "layout": "IPY_MODEL_4583c80496c645baa09584606007f53e"
          }
        },
        "67e437f3858f47c08dab7223acb4b0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d58ad456ea4b4289ad1f0d2a4ff256",
            "placeholder": "​",
            "style": "IPY_MODEL_f21369f542224bddafa6f3d9bd3ae5b8",
            "value": "Fetching 0 files: "
          }
        },
        "3fa75dbb80a240c8a71332448bdf2e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c18f28ee34546dc8a95c2c798019ccc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe2d48e4dcd84c19922d040f76e62a9b",
            "value": 0
          }
        },
        "4f93b0b47daf4f91b154236e2def63df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8887913f394babba83494a4fec7d74",
            "placeholder": "​",
            "style": "IPY_MODEL_3b88e96693d94028b534057b7d4ff4c8",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "4583c80496c645baa09584606007f53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d58ad456ea4b4289ad1f0d2a4ff256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21369f542224bddafa6f3d9bd3ae5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c18f28ee34546dc8a95c2c798019ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fe2d48e4dcd84c19922d040f76e62a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f8887913f394babba83494a4fec7d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b88e96693d94028b534057b7d4ff4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PDF & Lecture Summarizer + Question Bank Generator"
      ],
      "metadata": {
        "id": "KcXlfGFWFN6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "vuisJfEwFilN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8bjyaaTE_VW",
        "outputId": "17ccfac7-f198-4b1a-bd24-65a64200cc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentencepiece torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization Prototype"
      ],
      "metadata": {
        "id": "PmIwnP5jFmAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "LqeYVkSaFxo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarization model\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"sshleifer/distilbart-cnn-12-6\",\n",
        "    device=-1   # CPU only\n",
        ")\n",
        "\n",
        "\n",
        "# Example text (to bereplaced with your PDF text later)\n",
        "text = \"\"\"\n",
        "Natural language processing (NLP) is a subfield of\n",
        "linguistics, computer science, and artificial intelligence\n",
        "concerned with the interactions between computers\n",
        "and human language, how to program computers to\n",
        "process and analyze large amounts of natural language\n",
        "data. By “natural language” we mean a language that is used\n",
        "for everyday communication by humans, such as\n",
        "Arabic, English, Spanish….etc. NLP is not to be confused with the abbreviation that\n",
        "stands for Neuro-Linguistic Programming\n",
        " which is a psychological approach that involves\n",
        "analyzing strategies used by successful individuals and\n",
        "applying them to reach a personal goal\n",
        "\"\"\"\n",
        "\n",
        "# Summarize\n",
        "summary = summarizer(text, max_length=60, min_length=20, do_sample=False)\n",
        "print(\"Summary:\", summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paj_eWTtFsx_",
        "outputId": "a67bced2-b2be-4649-840f-493bef0728c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:  Natural language processing (NLP) is a subfield of computer science, computer science and artificial intelligence . By “natural language” we mean a language that is used for everyday communication by humans . NLP is not to be confused with the abbreviation Neuro-Linguistic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Generation Prototype"
      ],
      "metadata": {
        "id": "fZWtXEibGDOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Gq84LBo9GG0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question-generation model\n",
        "qg = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\", device=-1)\n",
        "\n",
        "\n",
        "# Example text\n",
        "context = \"\"\"\n",
        "NLP enables computers to understand and generate human language.\n",
        "One key technique is word embeddings, which represent words as vectors.\n",
        "Applications include chatbots, translation, and sentiment analysis.\n",
        "\"\"\"\n",
        "\n",
        "# Generate questions\n",
        "questions = qg(\"generate questions: \" + context, max_length=64, num_return_sequences=3)\n",
        "for i, q in enumerate(questions):\n",
        "    print(f\"Q{i+1}:\", q[\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hYTi301GEDG",
        "outputId": "73047277-3615-4aa4-fd38-0146c4d85d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: What does NLP allow computers to understand and generate human language?\n",
            "Q2: What does NLP enable computers to understand and generate human language?\n",
            "Q3: What does NLP allow computers to understand?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Text from Lecture PDFs"
      ],
      "metadata": {
        "id": "XMdetkwsHn8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used PyPDF2 to extract text."
      ],
      "metadata": {
        "id": "xv2kQaWqMNaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBfvok8MHup6",
        "outputId": "2fafbaf9-1e4f-41bb-b67f-1aeca4bfbd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract pillow pdf2image\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "import PyPDF2\n",
        "\n",
        "# Extract text with fallback OCR\n",
        "def extract_text_with_ocr(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text and page_text.strip():\n",
        "                text += page_text + \"\\n\"\n",
        "\n",
        "    # If text is empty -> run OCR\n",
        "    if not text.strip():\n",
        "        print(\"⚠️ No text found, using OCR...\")\n",
        "        pages = convert_from_path(pdf_path)   # convert PDF to images\n",
        "        for page in pages:\n",
        "            ocr_text = pytesseract.image_to_string(page)\n",
        "            text += ocr_text + \"\\n\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# Usage\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "pdf_text = extract_text_with_ocr(pdf_path)\n",
        "print(pdf_text[:1000])  # preview\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "zNK_S-pWHqxv",
        "outputId": "c1838e92-f3fd-4625-ed89-70f999cd5949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eee6d813-f4e5-46c2-8a4a-799046451a34\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eee6d813-f4e5-46c2-8a4a-799046451a34\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Intro for NLP_(NTI Lec 1).pdf to Intro for NLP_(NTI Lec 1) (6).pdf\n",
            "01\n",
            "\n",
            "Course Outline\n",
            "1.Introduction to NLP course and Basic Concepts\n",
            "2.NLP Basic Concepts\n",
            "3.NLP Basic Concepts\n",
            "4.Simple Processing\n",
            "02•Tokenization •Sentence\n",
            "•Segmentation •POS Tagging\n",
            "•Stemming •Lemmatization\n",
            "•Named Entity \n",
            "Recognition•Stop Words\n",
            "•Matchers •Text Visualization\n",
            "•Syntax Structure\n",
            "•Bag of Words •Text Vectors\n",
            "•TF-IDF5.Simple Processing\n",
            "6.Advanced Processing\n",
            "7.Modeling & Text Generation\n",
            "8.Modern NLP Architectures•Word Embedding •Word2Vec\n",
            "•Text Similarity •Distance Similarity\n",
            "• Text Classification •Text Clustering\n",
            "•LDA • N-Grams\n",
            "•Text Generation\n",
            "•Attention Mechanism •Transformer\n",
            "9.Large Language Models\n",
            "• LLMs (BERT, GPT) •Fine -tuning LLMs\n",
            "03•Introduction to Natural Language Processing\n",
            "•  What is Natural Language Processing (NLP)?\n",
            "• Natural Language Understanding(NLU) and Natural Language \n",
            "Generation(NLG) \n",
            "•Applications of Natural Language Processing(NLP) \n",
            "•Applications of Natural Language Understanding(NLU) \n",
            "•Applications of Natural Language Generation(NLG) \n",
            "•Challenges of nat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking Before Summarizing"
      ],
      "metadata": {
        "id": "CKlQFMbvJ57p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunked Long Texts :Broke down big lectures into smaller pieces so the models don’t crash."
      ],
      "metadata": {
        "id": "p4Y9U0OyMQV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, max_tokens=500):\n",
        "    words = text.split()\n",
        "    for i in range(0, len(words), max_tokens):\n",
        "        yield \" \".join(words[i:i+max_tokens])\n"
      ],
      "metadata": {
        "id": "-Q1YEz0KJ68k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used Hugging Face distilbart to generate lecture summaries:Combined summaries from chunks into one final summary."
      ],
      "metadata": {
        "id": "Ikg148cjMc6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = list(chunk_text(pdf_text, max_tokens=500))\n",
        "\n",
        "summaries = []\n",
        "for chunk in chunks:\n",
        "    summary = summarizer(chunk, max_length=120, min_length=40, do_sample=False)\n",
        "    summaries.append(summary[0]['summary_text'])\n",
        "\n",
        "final_summary = \" \".join(summaries)\n",
        "print(\"Final Summary:\\n\", final_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLB2nh3vJ9kJ",
        "outputId": "86710c1a-e4b4-4b02-cc0b-ab1102151e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Summary:\n",
            "  Course Outline: Introduction to NLP course and Basic Concepts . Introduction to Natural Language Processing . What is AI? What is Intelligence? How does natural language processing work? NLP is a difficult task because it involves a lot of unstructured data .  NLP is a field of Artificial Intelligence that enables computers to understand, interpret, and generate human language . NLP powers applications such as chatbots, translation services, sentiment analysis, and voice assistants like Siri and Alexa .  Low-resource language: Different businesses and industries often use very different language . NLP is word level analysis including: word segmentation, part-of-speech tagging (POS) oNamed Entity Recognition (NER) oStop Words Removal oStemming oLemmatization .  Semantic analysis would help computer learn about less literal meanings that go beyond the standard lexicon . Sentiment analysis is a way of measuring tone and intent in social media comments or reviews . It is often used on text data by businesses to monitor their customers’ feelings towards them and better understand customer needs .  Tokenization •Stemming •Lemmatization •Identifying Stop Words •Dependency Parsing •POS tags •Named Entity Recognition(NER) •Chunking 43 39 •Extract hashtags from a tweet .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarize the Lecture"
      ],
      "metadata": {
        "id": "wLvLJrqyIkn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated a Question Bank:Used Hugging Face t5-qg model: Created multiple questions from the lecture content."
      ],
      "metadata": {
        "id": "q9VkLOCfMoGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece torch PyPDF2\n",
        "from transformers import pipeline\n",
        "import PyPDF2\n",
        "\n",
        "# ----------------\n",
        "# 1. Load models\n",
        "# ----------------\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=-1)  # CPU mode for safety\n",
        "qg = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\", device=-1)\n",
        "\n",
        "# ----------------\n",
        "# 2. PDF Extract\n",
        "# ----------------\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# ----------------\n",
        "# 3. Chunking\n",
        "# ----------------\n",
        "def chunk_text(text, max_tokens=500):\n",
        "    words = text.split()\n",
        "    for i in range(0, len(words), max_tokens):\n",
        "        yield \" \".join(words[i:i+max_tokens])\n",
        "\n",
        "chunks = list(chunk_text(pdf_text))\n",
        "\n",
        "# ----------------\n",
        "# 4. Summarization\n",
        "# ----------------\n",
        "summaries = []\n",
        "for chunk in chunks:\n",
        "    try:\n",
        "        summary = summarizer(chunk, max_length=120, min_length=40, do_sample=False)\n",
        "        summaries.append(summary[0]['summary_text'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "final_summary = \" \".join(summaries)\n",
        "print(\"📌 Final Summary:\\n\", final_summary)\n",
        "\n",
        "# ----------------\n",
        "# 5. Question Generation\n",
        "# ----------------\n",
        "questions = []\n",
        "for chunk in chunks[:3]:   # limit to first 3 chunks for speed\n",
        "    try:\n",
        "        qset = qg(\"generate questions: \" + chunk, max_length=64, num_return_sequences=3)\n",
        "        questions.extend([q[\"generated_text\"] for q in qset])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"\\n📌 Generated Questions:\")\n",
        "for i, q in enumerate(questions):\n",
        "    print(f\"Q{i+1}:\", q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "os8icGtUIlbU",
        "outputId": "386ce140-65db-424d-8a56-adbb14f50e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3989a25-2611-449a-bdec-90a70e5bedd0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3989a25-2611-449a-bdec-90a70e5bedd0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Intro for NLP_(NTI Lec 1).pdf to Intro for NLP_(NTI Lec 1) (7).pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Final Summary:\n",
            "  Course Outline: Introduction to NLP course and Basic Concepts . Introduction to Natural Language Processing . What is AI? What is Intelligence? How does natural language processing work? NLP is a difficult task because it involves a lot of unstructured data .  NLP is a field of Artificial Intelligence that enables computers to understand, interpret, and generate human language . NLP powers applications such as chatbots, translation services, sentiment analysis, and voice assistants like Siri and Alexa .  Low-resource language: Different businesses and industries often use very different language . NLP is word level analysis including: word segmentation, part-of-speech tagging (POS) oNamed Entity Recognition (NER) oStop Words Removal oStemming oLemmatization .  Semantic analysis would help computer learn about less literal meanings that go beyond the standard lexicon . Sentiment analysis is a way of measuring tone and intent in social media comments or reviews . It is often used on text data by businesses to monitor their customers’ feelings towards them and better understand customer needs .  Tokenization •Stemming •Lemmatization •Identifying Stop Words •Dependency Parsing •POS tags •Named Entity Recognition(NER) •Chunking 43 39 •Extract hashtags from a tweet .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=64) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Generated Questions:\n",
            "Q1: What is the purpose of the NLP curriculum meeting?\n",
            "Q2: What is the purpose of the curriculum meeting?\n",
            "Q3: What is the name of the NLP curriculum meeting?\n",
            "Q4: What is the opposite direction of NLG?\n",
            "Q5: What is the opposite of NLG?\n",
            "Q6: What is the opposite direction of Natural Language Generation?\n",
            "Q7: What is the definition of Ambiguity Low-resource language?\n",
            "Q8: What is a low-resource language?\n",
            "Q9: What is the definition of Ambiguity Low-resource?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1) deps\n",
        "!pip install yake\n",
        "import re, random, pandas as pd, yake\n",
        "\n",
        "# === 2) helper: sentence splitter (no extra models needed)\n",
        "def split_sentences(text: str):\n",
        "    return [s.strip() for s in re.split(r'(?<=[.?!])\\s+', text.strip()) if s.strip()]\n",
        "\n",
        "# === 3) extract keywords from the summary (answers + distractor pool)\n",
        "kw_extractor = yake.KeywordExtractor(n=1, top=40)  # unigrams keep it simple/clean\n",
        "keywords = [kw for kw, _ in kw_extractor.extract_keywords(final_summary)]\n",
        "# keep only “real” terms\n",
        "keywords = [k for k in keywords if len(k) > 2 and re.search(r'[A-Za-z]', k)]\n",
        "\n",
        "# === 4) choose an answer present in a sentence\n",
        "def pick_answer(sent: str, kws):\n",
        "    for k in kws:\n",
        "        if re.search(rf'\\b{re.escape(k)}\\b', sent, flags=re.I):\n",
        "            return k\n",
        "    return None\n",
        "\n",
        "# === 5) generators for FIB / T-F / MCQ from one sentence + its answer\n",
        "def make_fib(sent: str, answer: str):\n",
        "    fib_q = re.sub(rf'\\b{re.escape(answer)}\\b', '____', sent, flags=re.I)\n",
        "    return {'type':'FIB', 'question': fib_q, 'answer': answer}\n",
        "\n",
        "def make_tf(sent: str, answer: str, kws):\n",
        "    flip = random.random() < 0.5\n",
        "    if flip and len(kws) > 1:\n",
        "        # replace answer with a random other keyword to make it false\n",
        "        distractor = random.choice([k for k in kws if k.lower() != answer.lower()])\n",
        "        stmt = re.sub(rf'\\b{re.escape(answer)}\\b', distractor, sent, flags=re.I)\n",
        "        return {'type':'T/F', 'question': f\"True or False: {stmt}\", 'answer': 'False'}\n",
        "    else:\n",
        "        return {'type':'T/F', 'question': f\"True or False: {sent}\", 'answer': 'True'}\n",
        "\n",
        "def make_mcq(sent: str, answer: str, kws):\n",
        "    pool = [k for k in kws if k.lower() != answer.lower()]\n",
        "    # safe sample ≤3 items\n",
        "    k = min(3, len(pool))\n",
        "    distractors = random.sample(pool, k) if k > 0 else []\n",
        "    options = distractors + [answer]\n",
        "    random.shuffle(options)\n",
        "    stem = re.sub(rf'\\b{re.escape(answer)}\\b', '_____', sent, flags=re.I)\n",
        "    # ask to fill the blank via options\n",
        "    q = f\"{stem}\\nChoose the best option to fill the blank.\"\n",
        "    return {'type':'MCQ', 'question': q, 'options': options, 'answer': answer}\n",
        "\n",
        "# === 6) build the bank from the SUMMARY\n",
        "def build_qbank_from_summary(summary_text: str, kws, max_per_type=10):\n",
        "    sents = split_sentences(summary_text)\n",
        "    tf_items, fib_items, mcq_items = [], [], []\n",
        "    for s in sents:\n",
        "        ans = pick_answer(s, kws)\n",
        "        if not ans:\n",
        "            continue\n",
        "        fib_items.append(make_fib(s, ans))\n",
        "        tf_items.append(make_tf(s, ans, kws))\n",
        "        mcq_items.append(make_mcq(s, ans, kws))\n",
        "        if len(fib_items) >= max_per_type and len(tf_items) >= max_per_type and len(mcq_items) >= max_per_type:\n",
        "            break\n",
        "    return tf_items, fib_items, mcq_items\n",
        "\n",
        "tf_items, fib_items, mcq_items = build_qbank_from_summary(final_summary, keywords, max_per_type=8)\n",
        "\n",
        "# === 7) flatten to a single CSV (type, question, options, answer)\n",
        "rows = []\n",
        "for it in tf_items:\n",
        "    rows.append({'type': 'T/F', 'question': it['question'], 'option_a': 'True', 'option_b': 'False',\n",
        "                 'option_c': '', 'option_d': '', 'answer': it['answer']})\n",
        "for it in fib_items:\n",
        "    rows.append({'type': 'FIB', 'question': it['question'], 'option_a': '', 'option_b': '',\n",
        "                 'option_c': '', 'option_d': '', 'answer': it['answer']})\n",
        "for it in mcq_items:\n",
        "    opts = (it['options'] + ['','','',''])[:4]\n",
        "    rows.append({'type': 'MCQ', 'question': it['question'],\n",
        "                 'option_a': opts[0], 'option_b': opts[1], 'option_c': opts[2], 'option_d': opts[3],\n",
        "                 'answer': it['answer']})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv('question_bank_enhanced.csv', index=False)\n",
        "print(\"✅ Saved question_bank_enhanced.csv with\", len(df), \"items\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQjs6L2AQDdM",
        "outputId": "2722df2f-c5a9-43d2-a907-a65dfe5631aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yake in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.12/dist-packages (from yake) (8.2.1)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.12/dist-packages (from yake) (1.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from yake) (3.5)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from yake) (2.0.2)\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.12/dist-packages (from yake) (1.5.11)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from yake) (0.9.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from segtok->yake) (2024.11.6)\n",
            "✅ Saved question_bank_enhanced.csv with 24 items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG prototype code"
      ],
      "metadata": {
        "id": "zumYZZlkV9Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkVLqFfWA83",
        "outputId": "5dcc6527-be3e-455e-de68-25582069f993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# load embedding model on CPU\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
        "\n",
        "# create embeddings for chunks\n",
        "chunk_texts = chunks  # from your earlier PDF splitting\n",
        "embeddings = embedder.encode(chunks, convert_to_tensor=False)\n",
        "\n",
        "import faiss, numpy as np\n",
        "emb_matrix = np.array(embeddings)\n",
        "dimension = emb_matrix.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(emb_matrix)\n",
        "\n",
        "# === 3) build FAISS index\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"✅ FAISS index built with\", index.ntotal, \"chunks\")\n",
        "\n",
        "# === 4) helper: ask a question\n",
        "from transformers import pipeline\n",
        "qa_model = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"distilbert-base-cased-distilled-squad\",\n",
        "    device=-1   # force CPU\n",
        ")\n",
        "\n",
        "\n",
        "def ask_question(question, top_k=3):\n",
        "    q_emb = embedder.encode([question], convert_to_tensor=False)\n",
        "    D, I = index.search(np.array(q_emb), k=top_k)\n",
        "    retrieved = \" \".join([chunks[idx] for idx in I[0]])\n",
        "\n",
        "    ans = qa_model(question=question, context=retrieved)\n",
        "    return ans[\"answer\"], retrieved\n",
        "\n",
        "\n",
        "\n",
        "# === 5) try it\n",
        "q = \"What is NLP and why is it difficult?\"\n",
        "ans, ctx = ask_question(q)\n",
        "print(\"Q:\", q)\n",
        "print(\"Answer:\", ans)\n",
        "print(\"\\nRetrieved Context:\", ctx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "818e87501e634a76956e3b321cf46419",
            "7080f098729540b6aa21f9a67423aa6e",
            "61004b4df7154c1288ed0e57d2ca9559",
            "b96c260e7af949ce98eb7d6a4023edac",
            "92f45af4e9a64a549f27bf7eebeabb79",
            "43b53feb54fb4bd3ac852cf2190c6a18",
            "e502db45e79f41378d35e0fc3cb2e704",
            "a3ed548d07174722bf72dac387c78927",
            "769f618ac31f4485af855bff573a01ef",
            "a154c595dc314126aadce8ec41640f17",
            "077ad37b972e4c4da0e0469dcc960a06",
            "217c98a8e4b54fa78852a9915f818530",
            "88f6c2c189bf41b2bb3a59dc57367b59",
            "767ede16753f4b4ab92bbaedd424287c",
            "37747e36e25547299466ca088222d0fc",
            "d2db485f93ca4f8cabf186838f313249",
            "12f71e581b1945ac9673ce13dc1a9bc1",
            "dec1996275714873964c55045b80aba1",
            "ad8d4028328f4d58a6a6c3f7f423b3cc",
            "edc1cb4ed1f54016a0736e61bf54b276",
            "3fb03d2c09ee425682fdb0d32c984a72",
            "63e46d4b205a4fe5a302d76f8200367b",
            "65c1e2c6f87140b5b2db45f8dcb60dd2",
            "67e437f3858f47c08dab7223acb4b0c8",
            "3fa75dbb80a240c8a71332448bdf2e78",
            "4f93b0b47daf4f91b154236e2def63df",
            "4583c80496c645baa09584606007f53e",
            "49d58ad456ea4b4289ad1f0d2a4ff256",
            "f21369f542224bddafa6f3d9bd3ae5b8",
            "7c18f28ee34546dc8a95c2c798019ccc",
            "fe2d48e4dcd84c19922d040f76e62a9b",
            "9f8887913f394babba83494a4fec7d74",
            "3b88e96693d94028b534057b7d4ff4c8"
          ]
        },
        "id": "TUb1tfb1V-Bp",
        "outputId": "3f1e5810-1883-4f21-8625-111f47bcb6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FAISS index built with 5 chunks\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "818e87501e634a76956e3b321cf46419"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "217c98a8e4b54fa78852a9915f818530"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65c1e2c6f87140b5b2db45f8dcb60dd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is NLP and why is it difficult?\n",
            "Answer: it involves a lot of unstructured data\n",
            "\n",
            "Retrieved Context: 01 Course Outline 1.Introduction to NLP course and Basic Concepts 2.NLP Basic Concepts 3.NLP Basic Concepts 4.Simple Processing 02•Tokenization •Sentence •Segmentation •POS Tagging •Stemming •Lemmatization •Named Entity Recognition•Stop Words •Matchers •Text Visualization •Syntax Structure •Bag of Words •Text Vectors •TF-IDF5.Simple Processing 6.Advanced Processing 7.Modeling & Text Generation 8.Modern NLP Architectures•Word Embedding •Word2Vec •Text Similarity •Distance Similarity • Text Classification •Text Clustering •LDA • N-Grams •Text Generation •Attention Mechanism •Transformer 9.Large Language Models • LLMs (BERT, GPT) •Fine -tuning LLMs 03•Introduction to Natural Language Processing • What is Natural Language Processing (NLP)? • Natural Language Understanding(NLU) and Natural Language Generation(NLG) •Applications of Natural Language Processing(NLP) •Applications of Natural Language Understanding(NLU) •Applications of Natural Language Generation(NLG) •Challenges of natural language processing •How does natural language processing work? •Evolution of NLP •NLP PipelineAgenda What is AI? 04 What is AI? 05 What is Intelligence? According to the theory of multiple intelligences proposed by Professor Howard Gardner, multiple intelligences are manifested by eight capabilities: oLinguistic -verbal intelligence oLogical -mathematical intelligence oVisual -spatial intelligence oBodily -kinesthetic intelligence oMusical -rhythmic and harmonic intelligence oInterpersonal intelligence oIntrapersonal intelligence oNaturalistic intelligence 06 What is AI? Artificial Intelligence (AI) is the field of computer science focused on creating systems or machines that can perform tasks that typically require human intelligence . These tasks include: – Learning (e.g., from data or experience) – Understanding language (Natural Language Processing) – Recognizing patterns and images (Computer Vision) – Making decisions (based on rules or data) – Controlling robots or autonomous systems 07 Popular AI Subfields 08 What is Natural Language Processing?•Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, how to program computers to process and analyze large amounts of natural language data. •By “natural language ” we mean a language that is used for everyday communication by humans, such as Arabic, English, Spanish ….etc. •NLP is not to be confused with the abbreviation that stands for Neuro -Linguistic Programming ( برمجة لغوية عصبية) which is a psychological approach that involves analyzing strategies used by successful individuals and applying them to reach a personal goal. 09 What is NLP? (cont.) •NLP is an Intersection of several fields oComputer Science o Artificial Intelligence o Linguistics •NLP is a difficult task because it involves a lot of unstructured data . •Understanding context is an issue in NLP– that requires semantic analysis and machine learning to get a handle on it. 10 Natural Language Processing Applications Why NLP? Question Answering Information Extraction Sentiment Analysis MachineTransl ation Information Retrieval and Search Engines Text Summarization Chatbots Email Spam Filtering Voice Assistants and Smart Homes AI ApplicationsNLP Applications 11 NLP Applications 1.Question Answering Question & Answer Demo Using BERT NLP for Arabic Language 12 NLP Applications 2.InformationExtraction Subject : curriculum meeting Date : January 15,2012 To: Dan Jurafsky Hi Dan, We’ve now scheduled the curriculum meeting . It will be in Gates 159 tomorrow from 10:00-‐11:30. Event: Curriculums Date: Jan -16-2012 Start: 10:00 am based on the structure of the sentence using the rules of formal grammar 44 How does NLP work? •Semantic analysis would help the computer learn about less literal meanings that go beyond the standard lexicon. This is often linked to sentiment analysis. •Sentiment analysis is a way of measuring tone and intent in social media comments or reviews. It is often used on text data by businesses so that they can monitor their customers ’ feelings towards them and better understand customer needs. o Simple emotion detection systems use lexicons – lists of words and the emotions they convey from positive to negative. More advanced systems use complex machine learning algorithms for accuracy. oThis is because lexicons may class a word like “killing ” as negative and so wouldn ’t recognize the positive connotations from a phrase like, “you guys are killing it ” (someone is doing very, very well) 45 Semantic Vs. Sentiment Analysis Semantic analysis is the study of the meaning of languageSentiment Analysis represents the emotional value of the text 46 How does NLP work?•Word sense disambiguation (WSD) is used to ascertain which sense of a word is being used in a sentence. Example of different context using the same word; o“The bank will not be accepting cash on Saturdays. ” o“The river overflowed the bank. ” 47 36NLP Evolution •In 1950 , Alan Turing published his famous paper “Computing Machinery and Intelligence ”, in which he introduced what is now known as the Turing Test . •In 1954 , the Georgetown Experiment was conducted in collaboration with IBM.It showcased one of the first fully automatic machine translation systems , translating more than 60 sentences from Russian to English . 37 •In 1968 , American computer scientist Terry Winograd at MIT developed a pioneering program called SHRDLU . •SHRDLU operated in a simple virtual world (called the blocks world) and was able to understand and respond to natural language commands . •It successfully engaged in context -aware dialogue with users, demonstrating a degree of politeness, coherence, and reasoning . 38Doctor Sbaitso – Early AI Psychologist Chatbot ( 1991 ) •In 1991 , a program called Doctor Sbaitso was developed as an early example of an AI- based psychologist chatbot . •It was designed to simulate a conversation with a therapist , running on MS-DOS systems . •While basic in intelligence, Doctor Sbaitso represented an early attempt to bring interactive NLP to personal computers and inspired future virtual assistants. 39Evolution of Virtual Personal Assistants ( 2011 –2017 ) •In 2011 , Apple launched Siri, the first widely adopted voice - enabled personal assistant for smartphones. •In 2014 , both Amazon Alexa and Microsoft Cortana were introduced, expanding the use of AI assistants to smart homes and Windows devices. •In 2016 , Google Assistant was launched, offering more advanced contextual understanding and integration with the Google ecosystem. •In 2017 , Samsung introduced Bixby, designed to provide device control and voice interaction across Samsung products. NLP Pipeline •Sentence Segmentation •Word End: 11:30 am Where: Gates 159 13 NLP Applications 3. Sentiment Analysis ✓ • nice and compact to carry! ✓ • since the camera is small and light, I won't need to carry 4 around those heavy, bulky professional cameras either! ✗ • the camera feels flimsy, is plastic and very light in weight you have to be very delicate in the handling of this camera 14 NLP Applications: 4.MachineTranslation Fully automatic Enter Source Text: 这不过是一个时间的问题 Translation from Stanford's Phrasal This is only a matter of time. Google Voice Translator: https://youtu.be/Pk 6a6mvOoJA Helping human translators by suggesting next words for example 15 NLP Applications: 5. Information Retrieval and Search Engines 16 NLP Applications: 6. Text Summarization Extractive Vs. Abstractive •Extractive: Identify and extract the important sections merely of the input text. • Abstractive: Produce new text in a generalized form and different structure. 17 NLP Applications: 6. Text Summarization Natural Language Processing (NLP) is a field of Artificial Intelligence that enables computers to understand, interpret, and generate human language. It combines computational linguistics with machine learning and deep learning models. NLP powers applications such as chatbots, translation services, sentiment analysis, and voice assistants like Siri and Alexa. It is widely used across industries such as healthcare, finance, and customer service to automate and enhance communication processes.NLP is a branch of AI that helps computers process and understand human language. It powers tools like chatbots and voice assistants and is used in various industries to improve communication. 18 NLP Applications: 7. Chatbots 19 NLP Applications: 7. Chatbots1.Facilitate Seamless Live Communication 2.Make Customer Service Available 24/7 3.Save Time and Money 4.Reduce People -to-People Interactions with Customers 5.Eliminate Tedious Time -Consuming Tasks 6.Offer a Smoother Customer Journey 7.Reduce Stress for Consumers 8.Eliminate Interactive Voice Response (IVR) Systems 9.Humanize Your Brand 10.Make Marketing More Targeted 11.Help Grow Your Business 12.Get Constant Improvement Over Time With Machine Learning Chatbots Advanced 20 NLP Applications: 8. Email Spam Filtering 21 NLP Applications: 9. Voice Assistants and Smart Homes •Amazon Alexa. ••Google Assistant: “Okay Google! ” https://youtu.be/hIHsgqID 9Xc https://youtu.be/ 81uyYKPpWww ••Apple Siri. ••Microsoft Cortana. • •Samsung Bixby: “Hey Bixby! ” https://youtu.be/pu 9QNm 5ITWg 22 23 NLP NLU NLG 24Natural Language Understanding (NLU) Natural language understanding (NLU) is a sub -branch of NLP and deals with these nuances via machine reading comprehension rather than simply understanding literal meanings. The aim of NLP and NLU is to help computers understand human language well enough that they can use language in a natural way. 25Natural Language Generation (NLG) •NLG is the opposite direction of NLU. •NLU reads while NLG writes. •NLU systems look at language and figure out what ideas are being communicated. •NLG systems start with a set of ideas locked in data and turn them into language that, in turn, communicates them •Usually need NLU to perform NLG! 26 NLU Application Intent Detection Question Answering Named Entity Recognition Sentiment Analysis NLG Application Dialogue System Code Generation Automatic Report Writing Image Capture 27Challenges and Limitations of NLP Contextual Synonyms Irony\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multi-document mode"
      ],
      "metadata": {
        "id": "peOjtnVubLAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Multi-document upload + processing ---\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # select multiple PDFs at once in the dialog\n",
        "\n",
        "docs = []\n",
        "for fname in uploaded.keys():\n",
        "    text = extract_text_with_ocr(fname)             # your OCR-aware function\n",
        "    if not text.strip():\n",
        "        continue\n",
        "\n",
        "    # per-doc chunking (keep chunks small for QA models)\n",
        "    doc_chunks = list(chunk_text(text, max_tokens=300))\n",
        "    # per-doc summary\n",
        "    doc_summaries = [summarizer(c, max_length=120, min_length=40, do_sample=False)[0]['summary_text']\n",
        "                     for c in doc_chunks]\n",
        "    doc_final_summary = \" \".join(doc_summaries)\n",
        "\n",
        "    docs.append({\n",
        "        \"name\": fname,\n",
        "        \"text\": text,\n",
        "        \"chunks\": doc_chunks,\n",
        "        \"summary\": doc_final_summary\n",
        "    })\n",
        "\n",
        "print(f\"✅ processed {len(docs)} documents\")\n",
        "\n",
        "# --- Global (cross-docs) summary + question bank ---\n",
        "overall_summary = \" \".join(d[\"summary\"] for d in docs)\n",
        "print(\"📌 overall summary (preview):\", overall_summary[:800], \"...\")\n",
        "\n",
        "# Rebuild the FIB/T-F/MCQ from the OVERALL summary (reuse your YAKE block)\n",
        "kw_extractor = yake.KeywordExtractor(n=1, top=50)\n",
        "keywords = [kw for kw,_ in kw_extractor.extract_keywords(overall_summary)]\n",
        "keywords = [k for k in keywords if len(k) > 2]\n",
        "\n",
        "tf_items, fib_items, mcq_items = build_qbank_from_summary(overall_summary, keywords, max_per_type=10)\n",
        "\n",
        "import pandas as pd\n",
        "rows = []\n",
        "for it in tf_items:\n",
        "    rows.append({'doc':'ALL','type':'T/F','question':it['question'],'option_a':'True','option_b':'False',\n",
        "                 'option_c':'','option_d':'','answer':it['answer']})\n",
        "for it in fib_items:\n",
        "    rows.append({'doc':'ALL','type':'FIB','question':it['question'],'option_a':'','option_b':'',\n",
        "                 'option_c':'','option_d':'','answer':it['answer']})\n",
        "for it in mcq_items:\n",
        "    opts = (it['options'] + ['','','',''])[:4]\n",
        "    rows.append({'doc':'ALL','type':'MCQ','question':it['question'],'option_a':opts[0],'option_b':opts[1],\n",
        "                 'option_c':opts[2],'option_d':opts[3],'answer':it['answer']})\n",
        "pd.DataFrame(rows).to_csv(\"question_bank_multi.csv\", index=False)\n",
        "print(\"✅ saved question_bank_multi.csv\")\n",
        "\n",
        "# --- Build a single FAISS index over ALL documents (keep doc ids) ---\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np, faiss\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
        "\n",
        "all_chunks, chunk_docids = [], []\n",
        "for i, d in enumerate(docs):\n",
        "    all_chunks.extend(d[\"chunks\"])\n",
        "    chunk_docids.extend([i]*len(d[\"chunks\"]))\n",
        "\n",
        "emb = embedder.encode(all_chunks, convert_to_numpy=True)\n",
        "index = faiss.IndexFlatL2(emb.shape[1])\n",
        "index.add(emb)\n",
        "print(\"✅ FAISS index built over\", len(all_chunks), \"chunks from\", len(docs), \"docs\")\n",
        "\n",
        "# --- Multi-doc Q&A helper (returns answer + which docs were used) ---\n",
        "def ask_question_multi(question, top_k=4):\n",
        "    q_emb = embedder.encode([question], convert_to_numpy=True)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    ctx_chunks = [all_chunks[i] for i in I[0]]\n",
        "    used_doc_ids = sorted(set(chunk_docids[i] for i in I[0]))\n",
        "\n",
        "    # keep context short enough for QA\n",
        "    context = \" \".join(ctx_chunks)[:2000]\n",
        "    ans = qa_model(question=question, context=context)\n",
        "    used_docs = [docs[j][\"name\"] for j in used_doc_ids]\n",
        "    return ans[\"answer\"], used_docs, ctx_chunks\n",
        "\n",
        "# try it\n",
        "ans, used_docs, ctx = ask_question_multi(\"What is Word2Vec?\", top_k=4)\n",
        "print(\"Answer:\", ans)\n",
        "print(\"From docs:\", used_docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "bf-p1FrxbLvY",
        "outputId": "e8a7dd27-597e-4c6f-cea5-c3a225c0adcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a08d736-541c-436f-bf1d-c30919121c0a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5a08d736-541c-436f-bf1d-c30919121c0a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving LLM & LangChain(NTI Lec 11).pdf to LLM & LangChain(NTI Lec 11).pdf\n",
            "Saving ocr&scraping(NTI Lec 12).pdf to ocr&scraping(NTI Lec 12).pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 14. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ processed 2 documents\n",
            "📌 overall summary (preview):  Large Language Models (LLMs) are advanced AI systems trained on massive text datasets . They understand, generate, translate, and summarize human language . Examples: GPT (by OpenAI), PaLM (by Google), LLaMA (by Meta ).  LangChain is an open -source framework for building applications powered by LLMs . It helps developers connect language models with external tools, data sources, and user interfaces . LangChain helps coordinate multiple LLM components into a single workflow .  LangChain uses LLMChains to chain multiple tasks (e.g., search → summarize → answer) to multiple tasks . Maintains memory/state across user interactions using: ConversationBufferMemory Vector stores + retrievers . Enables context -aware chatbots and assistants .  LangChain provides memory modules to store, retrieve, ...\n",
            "✅ saved question_bank_multi.csv\n",
            "✅ FAISS index built over 11 chunks from 2 docs\n",
            "Answer: Captured word relationships using vectors\n",
            "From docs: ['LLM & LangChain(NTI Lec 11).pdf', 'ocr&scraping(NTI Lec 12).pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Summary as PDF"
      ],
      "metadata": {
        "id": "XVAbzk_vLWs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CVv6OXuLicS",
        "outputId": "0a25d77b-1ebc-4197-efb7-1eba505552f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.3)\n",
            "Downloading reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas"
      ],
      "metadata": {
        "id": "oedQUftHLalq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "IdjtkRGmgFpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_text_as_pdf(text, filename):\n",
        "    c = canvas.Canvas(filename, pagesize=letter)\n",
        "    w, h = letter\n",
        "    t = c.beginText(40, h - 40)\n",
        "    t.setFont(\"Helvetica\", 12)\n",
        "    # simple wrapping\n",
        "    for para in text.split(\"\\n\"):\n",
        "        for line in [para[i:i+95] for i in range(0, len(para), 95)]:\n",
        "            t.textLine(line)\n",
        "        t.textLine(\"\")  # blank line between paragraphs\n",
        "    c.drawText(t); c.save()\n",
        "\n",
        "ts = time.strftime(\"%Y%m%d_%H%M\")"
      ],
      "metadata": {
        "id": "SLXks4pKgJFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) choose the newest summary\n",
        "summary_text = None\n",
        "summary_name = None\n",
        "if 'overall_summary' in globals() and overall_summary.strip():\n",
        "    summary_text = overall_summary\n",
        "    summary_name = f\"summary_overall_{ts}.pdf\"\n",
        "elif 'final_summary' in globals() and final_summary.strip():\n",
        "    summary_text = final_summary\n",
        "    summary_name = f\"summary_single_{ts}.pdf\"\n",
        "\n",
        "if summary_text:\n",
        "    save_text_as_pdf(summary_text, summary_name)\n",
        "    print(f\"✅ Saved summary -> {summary_name}\")\n",
        "    files.download(summary_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "oBERQTvcgNlr",
        "outputId": "4671e1cf-3ff0-40a2-bada-c24cca035961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved summary -> summary_overall_20250918_1105.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_203367bb-4dd4-420e-9ddb-24e98d83c9c6\", \"summary_overall_20250918_1105.pdf\", 3445)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Questions as CSV"
      ],
      "metadata": {
        "id": "MSK5eOmYLu5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) choose the newest question bank\n",
        "# Priority: (a) structured bank DataFrame df, (b) multi-doc CSV already created,\n",
        "# (c) fallback to open-ended `questions` list.\n",
        "if 'df' in globals() and isinstance(df, pd.DataFrame) and len(df):\n",
        "    qfile = f\"question_bank_enhanced_{ts}.csv\"\n",
        "    df.to_csv(qfile, index=False)\n",
        "    print(f\"✅ Saved enhanced question bank -> {qfile}\")\n",
        "    display(pd.read_csv(qfile).head(5))\n",
        "    files.download(qfile)\n",
        "elif os.path.exists(\"question_bank_multi.csv\"):\n",
        "    print(\"ℹ️ Using existing multi-doc bank: question_bank_multi.csv\")\n",
        "    display(pd.read_csv(\"question_bank_multi.csv\").head(5))\n",
        "    files.download(\"question_bank_multi.csv\")\n",
        "elif 'questions' in globals() and len(questions):\n",
        "    qfile = f\"question_bank_open_{ts}.csv\"\n",
        "    pd.DataFrame({'question': questions}).to_csv(qfile, index=False)\n",
        "    print(f\"✅ Saved open-ended question list -> {qfile}\")\n",
        "    display(pd.read_csv(qfile).head(5))\n",
        "    files.download(qfile)\n",
        "else:\n",
        "    print(\"⚠️ No question bank object found to save.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "-F6Pwvd1LyAw",
        "outputId": "572f7280-f819-4f9f-940e-e2d6fc842d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved enhanced question bank -> question_bank_enhanced_20250918_1105.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  type                                           question option_a option_b  \\\n",
              "0  T/F  True or False: Course Outline: Parsing to NLP ...     True    False   \n",
              "1  T/F  True or False: Introduction to Natural Languag...     True    False   \n",
              "2  T/F                    True or False: What is Natural?     True    False   \n",
              "3  T/F  True or False: How does natural Lemmatization ...     True    False   \n",
              "4  T/F  True or False: analysis is a difficult task be...     True    False   \n",
              "\n",
              "  option_c option_d answer  \n",
              "0      NaN      NaN  False  \n",
              "1      NaN      NaN   True  \n",
              "2      NaN      NaN  False  \n",
              "3      NaN      NaN  False  \n",
              "4      NaN      NaN  False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3949a50c-0e04-46dc-98ad-e5b1c0df3410\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>question</th>\n",
              "      <th>option_a</th>\n",
              "      <th>option_b</th>\n",
              "      <th>option_c</th>\n",
              "      <th>option_d</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T/F</td>\n",
              "      <td>True or False: Course Outline: Parsing to NLP ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T/F</td>\n",
              "      <td>True or False: Introduction to Natural Languag...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T/F</td>\n",
              "      <td>True or False: What is Natural?</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T/F</td>\n",
              "      <td>True or False: How does natural Lemmatization ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T/F</td>\n",
              "      <td>True or False: analysis is a difficult task be...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3949a50c-0e04-46dc-98ad-e5b1c0df3410')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3949a50c-0e04-46dc-98ad-e5b1c0df3410 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3949a50c-0e04-46dc-98ad-e5b1c0df3410');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ccded128-c5e4-4dc0-9462-67e039d234db\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ccded128-c5e4-4dc0-9462-67e039d234db')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ccded128-c5e4-4dc0-9462-67e039d234db button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_994fa570-cbba-4b6d-9f26-fe6abe47fd39\", \"question_bank_enhanced_20250918_1105.csv\", 2937)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
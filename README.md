# StudySpark-AI-Lecture-Assistant

# StudySpark: AI-Powered Lecture Study Assistant

[![Streamlit](https://img.shields.io/badge/Framework-Streamlit-red)](https://streamlit.io/)  
[![Hugging Face](https://img.shields.io/badge/Models-HuggingFace-yellow)](https://huggingface.co/)  
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)  
[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)  

---

## ğŸ“Œ Overview

**StudySpark** is a **comprehensive AI-powered lecture assistant** designed to help students, researchers, and professionals process lecture notes in PDF form. It combines **summarization, question bank generation, and Retrieval-Augmented Generation (RAG)-based Q&A** into a single streamlined app.

The application allows you to:

- Upload **multiple PDFs** (supports OCR for scanned docs).  
- Generate **clear, structured summaries** using `facebook/bart-large-cnn`.  
- Build a **Question Bank** with:
  - Multiple-Choice Questions (MCQs with distractors).  
  - True/False Questions.  
  - Fill-in-the-Blank (FIB) Questions.  
- Ask natural language questions about your notes with **RAG (FAISS + SentenceTransformers)**.  
- Export summaries and question banks to **PDF/CSV**.  
- Evaluate summarization quality with **ROUGE / BLEU metrics** against reference summaries.  

---

## ğŸš€ Features

| Feature                | Description                                                                 |
|-------------------------|-----------------------------------------------------------------------------|
| **PDF Upload**         | Drag & drop multiple PDFs; OCR-enabled via `pdf2image` + `pytesseract`.     |
| **Summarization**      | Uses Hugging Face BART (`facebook/bart-large-cnn`) with chunk-based pipeline.|
| **Question Bank**      | Keyword-based question generation (MCQ, T/F, FIB) via YAKE + regex.         |
| **RAG Q&A**            | Embeds text with `intfloat/e5-small-v2`, indexed in FAISS, retrieved for QA.|
| **Export**             | Summaries â†’ PDF (`reportlab`), Questions â†’ CSV (`pandas`).                  |
| **Evaluation**         | Compute **ROUGE-1, ROUGE-2, ROUGE-L, BLEU** vs reference summaries.         |
| **UI**                 | Streamlit-based multi-tab UI: Upload | Summarize | QBank | Ask | Export.     |

---

## ğŸ“‚ Project Structure

```
NTI_Final_Project/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py          # Paths, model configs, constants
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ embeddings.py        # FAISS + SentenceTransformer RAG backend
â”‚   â”œâ”€â”€ exporters.py         # PDF/CSV export utilities
â”‚   â”œâ”€â”€ pdf_loader.py        # PDF text + OCR extraction
â”‚   â”œâ”€â”€ question_generator.py# YAKE-based QBank generator
â”‚   â”œâ”€â”€ rag_qa.py            # RAG pipeline (retrieval + QA)
â”‚   â”œâ”€â”€ summarizer.py        # Summarization pipeline
â”‚   â”œâ”€â”€ text_processing.py   # Cleaning, chunking, sentence splitting
â”‚   â””â”€â”€ utils.py             # Timestamp helpers
â”œâ”€â”€ pdf-qa-app/
â”‚   â””â”€â”€ app.py               # Streamlit frontend
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/             # Raw uploaded PDFs
â”‚   â”œâ”€â”€ processed/           # Intermediate files
â”‚   â””â”€â”€ outputs/             # Exported summaries / CSVs
â””â”€â”€ requirements.txt         # Dependencies
```

---

## âš™ï¸ Installation

### 1. Clone Repository
```bash
git clone https://github.com/<your-username>/StudySpark-AI-Lecture-Assistant.git
cd StudySpark-AI-Lecture-Assistant
```

### 2. Create Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate     # Linux / Mac
.venv\Scripts\activate.ps1    # Windows PowerShell
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Install System Dependencies
- **Poppler** â†’ required by `pdf2image` (PDF â†’ images).  
- **Tesseract OCR** â†’ required for OCR on scanned PDFs.  

**Ubuntu / Debian**
```bash
sudo apt-get install poppler-utils tesseract-ocr
```

**MacOS (Homebrew)**
```bash
brew install poppler tesseract
```

**Windows**
- Install [Poppler for Windows](http://blog.alivate.com.au/poppler-windows/).  
- Install [Tesseract OCR](https://github.com/UB-Mannheim/tesseract/wiki).  

---

## â–¶ï¸ Running the App

From project root:

```bash
streamlit run pdf-qa-app/app.py --server.enableXsrfProtection=false --server.enableCORS=false
```

- Open in browser: [http://localhost:8501](http://localhost:8501)  

---
---

## ğŸ”„ Full Project Flow

The following diagram and step-by-step explanation describe the **end-to-end workflow** of StudySpark.

### ğŸ“ High-Level Architecture

```text
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   PDF Upload  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ OCR Extraction â”‚â”€â”€â”€â–º [Tesseract + Poppler] (if scanned PDF)
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Text Cleaningâ”‚â”€â”€â”€â–º remove noise, normalize, preprocess
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Text Chunking â”‚â”€â”€â”€â–º ~300 tokens per chunk
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º (1) Summarization
                  â”‚
                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º (2) Question Bank Generation
                  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º (3) Vector Indexing (FAISS)
```

---

### 1. **Document Ingestion**
- User uploads **1 or more PDFs**.  
- For **native PDFs** â†’ extract text using `PyPDF2`.  
- For **scanned PDFs** â†’ convert pages into images via `pdf2image` â†’ run **OCR** with `pytesseract`.  
- All extracted text is normalized with `text_processing.clean_text()`.  

---

### 2. **Chunking**
- Long documents are split into **chunks (~300 tokens)** to avoid exceeding model context windows.  
- Each chunk is stored in memory with a reference to its **document ID**.  

Equation:
```math
chunks = âŒˆ total_tokens / chunk_size âŒ‰
```

---

### 3. **Summarization**
- Each chunk is fed into **BART (`facebook/bart-large-cnn`)** summarizer.  
- Individual summaries are concatenated and **refined again** for a **cleaner overall summary**.  

Pipeline:
```text
Chunk â†’ BART â†’ Chunk Summary
...
All Chunk Summaries â†’ BART â†’ Overall Summary
```

---

### 4. **Question Bank Generation**
- From the overall summary:
  - **YAKE** extracts top keywords (`topk=50`).  
  - For each keyword, generate:
    - **MCQs** (distractors chosen from other keywords).  
    - **True/False** questions (random perturbations).  
    - **Fill-in-the-Blank** (keyword blanked).  
- Output â†’ `pandas.DataFrame` with: *[Question | Type | Options | Answer]*.  

---

### 5. **Vector Indexing (RAG)**
- All chunks are embedded using `intfloat/e5-small-v2`.  
- Embeddings stored in **FAISS Index (IndexFlatIP, cosine similarity)**.  
- Each embedding keeps a pointer back to its **source chunk**.  

Equation:
```math
similarity(query, chunk) = (u Â· v) / (||u|| ||v||)
```

---

### 6. **Retrieval-Augmented Q&A**
- User types a question.  
- Query is embedded and searched against FAISS.  
- Top-k chunks are retrieved.  
- Retrieved chunks + question â†’ passed into **DistilBERT (SQuAD fine-tuned)** for answer extraction.  

Pipeline:
```text
User Question â†’ Encode â†’ FAISS Search â†’ Retrieve Chunks â†’ DistilBERT â†’ Answer
```

---

### 7. **Export**
- **Summaries** exported as PDF via `reportlab`.  
- **Question Bank** exported as CSV.  
- Filenames timestamped (`utils.ts()`).  

---

### 8. **Evaluation (Optional)**
- Summaries can be evaluated against human references using **ROUGE & BLEU**.  
- Metrics provide quantitative insights into summarization performance.  

---

âœ… This modular design ensures **scalability**:  
- You can swap summarization models (e.g., T5, Pegasus).  
- Replace FAISS with **Pinecone / Weaviate** for cloud-scale retrieval.  
- Plug in GPT-style large language models for improved Q&A.  
 
## ğŸ” Usage Flow

1. **Upload PDFs**  
   - Supports multiple documents.  
   - OCR fallback if no text is extracted.  

2. **Summarization**  
   - Per-document summary.  
   - Combined overall summary.  

3. **Question Bank**  
   - Auto-generated MCQs, T/F, and FIBs.  
   - Configurable number per type.  

4. **Ask (RAG)**  
   - Query your lecture notes.  
   - Uses FAISS + embeddings for retrieval.  
   - QA model extracts answers.  

5. **Export**  
   - Summaries â†’ PDF.  
   - Questions â†’ CSV.  

---

## ğŸ§  Technical Details

### Summarization
- Model: `facebook/bart-large-cnn`  
- Pipeline: Hugging Face `transformers.pipeline("summarization")`  
- Chunking: `chunk_text` splits into ~300 tokens.  
- Refinement: Multi-stage summarization (chunk â†’ merge â†’ refine).  

Equation for word count split:
```math
chunks = âŒˆ len(words) / max_tokens âŒ‰
```

### Question Bank
- **Keyword Extraction:** YAKE (`KeywordExtractor(n=1, top=50)`).  
- **MCQ Generation:** Sentence with keyword blanked, distractors from other keywords.  
- **T/F Generation:** Randomly replace keyword with distractor for "False".  
- **FIB Generation:** Replace keyword with `"____"`.  

### RAG Q&A
- Embedding model: `intfloat/e5-small-v2` (SentenceTransformers).  
- Retrieval backend: FAISS `IndexFlatIP` (cosine similarity).  
- QA model: `distilbert-base-cased-distilled-squad`.  
- Query flow:
  ```text
  Question â†’ Encode â†’ Search FAISS â†’ Retrieve Top-k Chunks â†’ QA Model
  ```

Equation for similarity:
```math
cosine(u, v) = (u Â· v) / (||u|| ||v||)
```

---

## ğŸ“Š Evaluation (ROUGE / BLEU)

You can evaluate summarization with gold reference summaries.

### Metrics
| Metric    | Definition |
|-----------|------------|
| **ROUGE-1** | Overlap of unigrams between candidate and reference. |
| **ROUGE-2** | Overlap of bigrams. |
| **ROUGE-L** | Longest common subsequence (LCS). |
| **BLEU**    | Precision-based n-gram metric with brevity penalty. |

### Example Usage
```python
from datasets import load_metric

rouge = load_metric("rouge")
bleu = load_metric("bleu")

candidate = "Deep learning models are powerful."
reference = ["Deep learning is a powerful approach."]

rouge_score = rouge.compute(predictions=[candidate], references=[reference])
bleu_score = bleu.compute(predictions=[candidate.split()], references=[[reference[0].split()]])
print(rouge_score, bleu_score)
```

---

## ğŸ“¦ Requirements

```
streamlit
torch
transformers
sentence-transformers
faiss-cpu
pandas
numpy
PyPDF2
pdf2image
pytesseract
Pillow
reportlab
yake
```

---

## ğŸ§ª Example Run

### Uploaded PDF
ğŸ“„ `intro_nlp.pdf` (Lecture notes on NLP basics)

### Output
- **Summary:**
```
Natural Language Processing (NLP) involves preprocessing, embeddings, and transformers...
```

- **Sample Question Bank:**
| Type | Question | Options | Answer |
|------|----------|---------|--------|
| MCQ  | NLP is about _____. Choose the best option. | [Text, Vision, Sound, NLP] | NLP |
| T/F  | True or False: NLP deals with language understanding. | True/False | True |
| FIB  | NLP involves _____. | Language | Language |

- **Q&A:**
```
Q: What is tokenization?
A: The process of splitting text into tokens such as words or subwords.
```



## ğŸ™Œ Acknowledgments

- Hugging Face `transformers`  
- SentenceTransformers library  
- Streamlit team  
- FAISS (Facebook AI Similarity Search)  
- YAKE (Yet Another Keyword Extractor)  
- ReportLab for PDF exports  
